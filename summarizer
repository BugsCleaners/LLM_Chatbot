```bash
apt update && apt install python3-pip -y
```

```bash
mkdir llm-summarizer
cd llm-summarizer
```

```bash
cat >requirements.txt <<EOF
transformers>=4.37.0
torch>=2.1.0
accelerate>=0.25.0
einops>=0.7.0
jinja2>=3.1.0
EOF
```

```bash
pip install -r requirements.txt
```

```bash
cat>llm-summarizer.py<<EOF

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from transformers import pipeline

model = AutoModelForSeq2SeqLM.from_pretrained(
        "Falconsai/text_summarization",  # Using a model suitable for summarization
        device_map="auto",
        torch_dtype="auto",
        trust_remote_code=True,
        )
tokenizer = AutoTokenizer.from_pretrained("Falconsai/text_summarization")

summarizer = pipeline(
        "summarization",
        model=model,
        tokenizer=tokenizer,
        max_length=150,  # Adjust max_length as needed for summarization
        min_length=30,
        do_sample=False
        )
        
user_input = input("Enter the text you want to summarize:")
response = summarizer(user_input)
print(response[0]["summary_text"])

EOF
```

```bash
python3 llm-summarizer.py
```

loop

```bash
cat>llm-summarizer.py<<EOF

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from transformers import pipeline
model = AutoModelForSeq2SeqLM.from_pretrained(
        "Falconsai/text_summarization",  # Using a model suitable for summarization
        device_map="auto",
        torch_dtype="auto",
        trust_remote_code=True,
        )
tokenizer = AutoTokenizer.from_pretrained("Falconsai/text_summarization")

summarizer = pipeline(
        "summarization",
        model=model,
        tokenizer=tokenizer,
        max_length=150,  # Adjust max_length as needed for summarization
        min_length=30,
        do_sample=False
        )
        
user_input = input("Enter the text you want to summarize:")
response = summarizer(user_input)
print(response[0]["summary_text"])

while True:
    print("-" *50) # Horizontal line
    user_input = input("\033[92mEnter the text you want to summarize: \033[0m") # Ask the user for input in green color
    if user_input in ['X', 'x']: # If user types X or x, exit the program
        print("Exiting.")
        break
    else:
        print("-" *50)
        print("Calling LLM for summarizing")
        response = summarizer(user_input)
        print(response[0]["summary_text"])
        
EOF
```

```bash
python3 llm-summarizer.py
```

file and web 

```bash
wget -O llm-summarizer.py https://gitlab.practical-devsecops.training/-/snippets/58/raw/main/llm-summarizer.py
python3 llm-summarizer.py
```

```bash
cat>llm-summarizerweb.py<<EOF

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model = AutoModelForSeq2SeqLM.from_pretrained(
        "Falconsai/text_summarization",  # Using a model suitable for summarization
        device_map="auto",
        torch_dtype="auto",
        trust_remote_code=True,
        )
    
tokenizer = AutoTokenizer.from_pretrained("Falconsai/text_summarization")

from transformers import pipeline

summarizer = pipeline(
        "summarization",
        model=model,
        tokenizer=tokenizer,
        max_length=150,  # Adjust max_length as needed for summarization
        min_length=30,
        do_sample=False
        )

import requests

while True:
    print("-" *50) # Horizontal line
    user_input = input("\033[92mEnter a file path (file://) or a URL (http:// or https://): \033[0m")

    if user_input in ['X', 'x']: # If user types X or x, exit the program
        print("Exiting.")
        break
    else:
        if user_input.startswith("file://"):
            with open(user_input[7:], 'r') as file:  # Skip 'file://' prefix
                user_input = file.read()
        elif user_input.startswith("http://") or user_input.startswith("https://"):
            response = requests.get(user_input)
            user_input = response.text
        else:
            print("Invalid input. Please start with file:// or http:///https://.")
            continue

        print("-" *50)
        print("Calling LLM")
        response = summarizer(user_input)
        print(response[0]["summary_text"])

EOF
```

```bash
python3 llm-summarizerweb.py
```

```bash
wget -O Saturnalia.txt https://gitlab.practical-devsecops.training/-/snippets/59/raw/main/Saturnalia.txt

wget -O Mephistopheles.txt https://gitlab.practical-devsecops.training/-/snippets/60/raw/main/Mephistopheles.txt

wget -O VincentVanGogh.txt https://gitlab.practical-devsecops.training/-/snippets/61/raw/main/VincentVanGogh.txt
```

```bash
python3 llm-summarizerweb.py
```

```bash
file://Saturnalia.txt
file://Mephistopheles.txt
file://VincentVanGogh.txt
```

```bash
python3 llm-summarizer.py
```

```bash
https://gitlab.practical-devsecops.training/-/snippets/53/raw/main/Cormorants.txt
https://gitlab.practical-devsecops.training/-/snippets/54/raw/main/Albatross.txt
https://gitlab.practical-devsecops.training/-/snippets/55/raw/main/Conures.txt
https://gitlab.practical-devsecops.training/-/snippets/56/raw/main/BallPython.txt
https://gitlab.practical-devsecops.training/-/snippets/57/raw/main/Snakes.txt
```
